# ğŸ‘©ğŸ»â€ğŸ’» Maryam Zaidi  

**Computational Oncology | Interpretable AI | Medical Imaging | Federated Learning**  
Ajman, UAE  
ğŸ“§ maryamfatimaa.06@gmail.com  
ğŸ”— [LinkedIn](https://www.linkedin.com/in/maryamzaidii)  
ğŸŒ [Portfolio Website](https://maryamfatima02.github.io)

---

## ğŸ§  About Me  

I am a Computing Science undergraduate with a focused research interest in AI-driven medical diagnostics, particularly in interpretable and privacy-preserving systems for early cancer detection.

My work centers on building clinically responsible machine learning pipelines that bridge computational intelligence with real-world healthcare challenges.

### Research Interests
- Computational Oncology  
- Multi-modal Learning  
- Explainable AI (XAI)  
- Federated Learning for Healthcare  
- Non-invasive Medical Imaging Diagnostics  

---

# ğŸ”¬ Research Work  

## ğŸ©º Dual-Modality Interpretable AI Framework for Breast Cancer Triage  

**Primary Author**  
Abstract accepted at ICPACT 2026 â€“ Amity University Dubai  

This research explores an interpretable dual-modality AI system for early breast cancer detection integrating:

- Classical ML models on FNA cytology dataset (569 samples)
- Hybrid VGG16â€“Vision Transformer architecture for ultrasound imaging
- Explainable AI techniques (SHAP)
- Federated Learning simulation for privacy-preserving training

---

### ğŸ” FNA Cytology ML Pipeline  

- Built preprocessing workflow:
  - Missing value imputation  
  - Stratified train-test splitting  
  - Feature scaling  
- Evaluated 7 supervised classifiers:
  - Logistic Regression  
  - Support Vector Machine  
  - Random Forest  
  - k-Nearest Neighbors  
- Logistic Regression achieved highest AUROC.
- Model evaluation using:
  - Sensitivity & Specificity  
  - ROC-AUC  
  - Confusion matrices  
  - Cross-validation  
- Applied SHAP for model interpretability.

**Objective:**  
Develop clinically interpretable models suitable for real-world triage systems.

---

### ğŸ§  Hybrid Vision Transformer â€“ Ultrasound Imaging  

- Implemented hybrid CNN + Vision Transformer architecture.
- Compared transfer learning vs training from scratch.
- Studied feature extraction efficiency in small medical datasets.
- Focused on diagnostic robustness and generalization.

---

### ğŸ” Federated Learning Simulation  

- Built decentralized training prototype simulating distributed hospital learning.
- Compared centralized vs federated model performance.
- Analyzed communication efficiency and convergence behavior.
- Emphasized privacy preservation for sensitive medical datasets.

---

# ğŸ’» Projects  

## ğŸ”— Snap Link Extractor & Downloader  

Python-based automation tool designed to:

- Extract downloadable media URLs from structured web content.
- Parse HTML responses and identify embedded links.
- Automate batch download workflows.
- Improve efficiency in structured data extraction tasks.

### Technologies Used:
- Python  
- Requests  
- HTML Parsing  
- File System Automation  

This project strengthened my understanding of web data extraction and automation pipelines.

---

# ğŸŒ Portfolio Website  

My academic portfolio is hosted at:

ğŸ‘‰ https://maryamfatima02.github.io  

The website includes:
- Research interests  
- Publication details  
- Project documentation  
- Technical skills overview  
- Contact information  

---

# ğŸ›  Technical Skills  

**Languages:** Python, Java, SQL  
**ML Libraries:** scikit-learn, SHAP  
**Data Processing:** Imputation, Stratified Splits, Cross-validation  
**Evaluation Metrics:** AUROC, Sensitivity, Specificity  
**Tools:** Git, Jupyter Notebook, Google Colab  

---

# ğŸ¯ Research Vision  

I am driven by the belief that subtle biological signals can encode profound insights about human health. My long-term goal is to contribute to AI systems that enhance early diagnosis, improve clinical trust, and responsibly integrate machine learning into healthcare decision-making.

If you are interested in collaboration or discussion in computational oncology or medical AI, feel free to connect.

---

# ğŸ“Œ Upcoming Work  

- Full paper submission (ICPACT 2026)  
- Expanding federated training experiments  
- Exploring multi-modal extensions with retinal imaging  

---
